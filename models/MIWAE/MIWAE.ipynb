{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a052eda1-72a8-4949-938c-53ce50932033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 20:07:26.974139: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07633e9a-f931-4455-9bab-7e3e3e1156a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmiss = pd.read_csv('data_50/data_50_v1/bean/bean_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3928847-774e-4061-a11f-983bd96d03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfull = pd.read_csv('data_50/data_50_v1/bean/bean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff52f2b-efe2-48f0-923b-d0495b37d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.read_csv('data_50/data_50_v1/bean/bean_sign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9676fbb-0e63-4199-9cde-5be1225236e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_0 = np.copy(xmiss)\n",
    "xhat_0[np.isnan(xmiss)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d06fa70-ea6b-4513-8e84-f0cfce550683",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_0 = np.array(xhat_0).astype(np.float32)\n",
    "mask = np.array(mask).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def43bc8-b904-4d3f-8587-fb00613607dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 20:07:30.422947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 20:07:31.173282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10102 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:d6:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "d = 10 # 10D manifold\n",
    "p_z = tfd.MultivariateNormalDiag(loc=tf.zeros(d, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95ef5e7-4ddc-4840-b2b8-9444bb12d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = xfull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5618402-22fb-4bd2-b8b0-7d84461f9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 128 # number of hidden units (same for all MLPs)\n",
    "\n",
    "sigma = \"relu\"\n",
    "\n",
    "decoder = tfk.Sequential([\n",
    "  tfkl.InputLayer(input_shape=[d,]),\n",
    "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"he_normal\"),\n",
    "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"he_normal\"),\n",
    "  tfkl.Dense(3*p,kernel_initializer=\"he_normal\") # the decoder will output both the mean, the scale, and the number of degrees of freedoms (hence the 3*p)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906d7eda-fff4-408c-8740-83d1d28c20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iota = tf.Variable(np.zeros([1,p]),dtype=tf.float32) # this will be updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f7448d2-e2f2-4e44-8e2e-f1041f6ff33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfk.Sequential([\n",
    "  tfkl.InputLayer(input_shape=[p,]),\n",
    "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"he_normal\"),\n",
    "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"he_normal\"),\n",
    "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"he_normal\"),\n",
    "  tfkl.Dense(3*d,kernel_initializer=\"he_normal\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c234cb00-8103-46de-9a1b-ea642208dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def miwae_bound(xhat_0_batch, mask_batch,K):\n",
    "\n",
    "    tiledmask = tf.tile(mask_batch,[K,1])\n",
    "    mask_complement_float = tf.abs(mask_batch-1)\n",
    "\n",
    "    tilediota = tf.tile(iota,[xhat_0_batch.shape[0],1])\n",
    "    iotax = xhat_0_batch + tf.multiply(tilediota,mask_complement_float)\n",
    "\n",
    "    out_encoder = encoder(iotax)\n",
    "    q_zgivenxobs = tfd.Independent(distribution=tfd.StudentT(loc=out_encoder[..., :d], scale=tf.nn.softplus(out_encoder[..., d:(2*d)]), df=3 + tf.nn.softplus(out_encoder[..., (2*d):(3*d)])))\n",
    "    zgivenx = q_zgivenxobs.sample(K)\n",
    "    zgivenx_flat = tf.reshape(zgivenx,[K*xhat_0_batch.shape[0],d])\n",
    "\n",
    "    out_decoder = decoder(zgivenx_flat)\n",
    "    data_flat = tf.reshape(tf.tile(xhat_0_batch,[K,1]),[-1,1])\n",
    "    all_means_obs_model = out_decoder[..., :p]\n",
    "    all_scales_obs_model = tf.nn.softplus(out_decoder[..., p:(2*p)]) + 0.001\n",
    "    all_degfreedom_obs_model = tf.nn.softplus(out_decoder[..., (2*p):(3*p)]) + 3\n",
    "    all_log_pxgivenz_flat = tfd.StudentT(loc=tf.reshape(all_means_obs_model,[-1,1]),scale=tf.reshape(all_scales_obs_model,[-1,1]),df=tf.reshape(all_degfreedom_obs_model,[-1,1])).log_prob(data_flat)\n",
    "    all_log_pxgivenz = tf.reshape(all_log_pxgivenz_flat,[K*xhat_0_batch.shape[0],p])\n",
    "\n",
    "    logpxobsgivenz = tf.reshape(tf.reduce_sum(tf.multiply(all_log_pxgivenz,tiledmask),1),[K,xhat_0_batch.shape[0]])\n",
    "    logpz = p_z.log_prob(zgivenx)\n",
    "    logq = q_zgivenxobs.log_prob(zgivenx)\n",
    "\n",
    "    average_miwae_bound = tf.reduce_mean(tf.reduce_logsumexp(logpxobsgivenz + logpz - logq,0) -tf.math.log(tf.cast(K,tf.float32)) ) \n",
    "    return average_miwae_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0738afe9-1bf1-453a-90de-d667204e2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def miwae_impute(xhat_0_batch, mask_batch,L=1000,kind=\"single\",num_samples=20):\n",
    "\n",
    "    # kind = \"single\" will return only the single imputation\n",
    "    # kind = \"multiple\" will return num_samples multiple imputations\n",
    "    # kind = \"both\" will both the single imputation and num_samples multiple imputations\n",
    "\n",
    "    tiledmask = tf.tile(mask_batch,[L,1])\n",
    "    mask_complement_float = tf.abs(mask_batch-1)\n",
    "\n",
    "    tilediota = tf.tile(iota,[xhat_0_batch.shape[0],1])\n",
    "    iotax = xhat_0_batch + tf.multiply(tilediota,mask_complement_float)\n",
    "\n",
    "    out_encoder = encoder(iotax)\n",
    "    q_zgivenxobs = tfd.Independent(distribution=tfd.StudentT(loc=out_encoder[..., :d], scale=tf.nn.softplus(out_encoder[..., d:(2*d)]), df=3 + tf.nn.softplus(out_encoder[..., (2*d):(3*d)])))\n",
    "    zgivenx = q_zgivenxobs.sample(L)\n",
    "    zgivenx_flat = tf.reshape(zgivenx,[L*xhat_0_batch.shape[0],d])\n",
    "\n",
    "    out_decoder = decoder(zgivenx_flat)\n",
    "    data_flat = tf.reshape(tf.tile(xhat_0_batch,[L,1]),[-1,1])\n",
    "    all_means_obs_model = out_decoder[..., :p]\n",
    "    all_scales_obs_model = tf.nn.softplus(out_decoder[..., p:(2*p)]) + 0.001\n",
    "    all_degfreedom_obs_model = tf.nn.softplus(out_decoder[..., (2*p):(3*p)]) + 3\n",
    "    xgivenz = tfd.Independent(distribution=tfd.StudentT(loc=all_means_obs_model, scale=all_scales_obs_model, df=all_degfreedom_obs_model))\n",
    "    all_log_pxgivenz_flat = tfd.StudentT(loc=tf.reshape(all_means_obs_model,[-1,1]),scale=tf.reshape(all_scales_obs_model,[-1,1]),df=tf.reshape(all_degfreedom_obs_model,[-1,1])).log_prob(data_flat)\n",
    "    all_log_pxgivenz = tf.reshape(all_log_pxgivenz_flat,[L*xhat_0_batch.shape[0],p])\n",
    "\n",
    "    logpxobsgivenz = tf.reshape(tf.reduce_sum(tf.multiply(all_log_pxgivenz,tiledmask),1),[L,xhat_0_batch.shape[0]])\n",
    "    logpz = p_z.log_prob(zgivenx)\n",
    "    logq = q_zgivenxobs.log_prob(zgivenx)\n",
    "\n",
    "    log_imp_weights = logpxobsgivenz + logpz - logq # same importance wieghts used for single and multiple imputation\n",
    "\n",
    "    if ((kind==\"single\") or (kind==\"both\")):\n",
    "\n",
    "        imp_weights = tf.nn.softmax(log_imp_weights,0) # these are w_1,....,w_L for all observations in the batch\n",
    "        xms = tf.reshape(xgivenz.mean(),[L,xhat_0_batch.shape[0],p])\n",
    "        xm = xhat_0_batch + tf.multiply(tf.einsum('ki,kij->ij', imp_weights, xms),mask_complement_float)\n",
    "\n",
    "    if ((kind==\"multiple\") or (kind==\"both\")):\n",
    "\n",
    "        sir_logits = tf.transpose(log_imp_weights)\n",
    "        sir = tfd.Categorical(logits = sir_logits).sample(num_samples)\n",
    "        xmul = tf.reshape(xhat_0_batch + tf.multiply(tf.reshape(xgivenz.sample(),[L,xhat_0_batch.shape[0],p]),mask_complement_float),[L,xhat_0_batch.shape[0],p])\n",
    "    if (kind==\"single\"):\n",
    "        return xm\n",
    "\n",
    "    if (kind==\"multiple\"):\n",
    "        return tf.gather(tf.transpose(xmul,perm=[1,0,2]), tf.transpose(sir), axis = 1, batch_dims=1)\n",
    "\n",
    "    if (kind==\"both\"):\n",
    "        return xm, tf.gather(tf.transpose(xmul,perm=[1,0,2]), tf.transpose(sir), axis = 1, batch_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb56820-a2d8-4862-8f87-0288212d9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27bb9c47-b3fb-43f0-af3f-7630bd928d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = encoder.trainable_variables + decoder.trainable_variables + [iota]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eace9a52-73d4-4e0d-b526-b66e02a80efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def gradient_step_miwae(xhat_0_batch, mask_batch,K):\n",
    "      with tf.GradientTape() as tape: # the gradient tape saves all the step that needs to be saved fopr automatic differentiation\n",
    "        loss = -  miwae_bound(xhat_0_batch, mask_batch,K)  # the loss is the negative ELBO\n",
    "      gradients = tape.gradient(loss, all_parameters)  # here, the gradient is automatically computed\n",
    "      optimizer.apply_gradients(zip(gradients, all_parameters))  # Adam iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4543be-2ed0-4c6d-83d7-4dce93d959f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((xhat_0,mask)).shuffle(n).batch(32) # TF creates the batches for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597da54b-4fbf-45c9-a87d-2be91e6bdbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.\n",
      "Instructions for updating:\n",
      "Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 20:07:34.919124: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "Epoch  2\n",
      "Epoch  3\n",
      "Epoch  4\n",
      "Epoch  5\n",
      "Epoch  6\n",
      "Epoch  7\n",
      "Epoch  8\n",
      "Epoch  9\n",
      "Epoch  10\n",
      "Epoch  11\n",
      "Epoch  12\n",
      "Epoch  13\n",
      "Epoch  14\n",
      "Epoch  15\n",
      "Epoch  16\n",
      "Epoch  17\n",
      "Epoch  18\n",
      "Epoch  19\n",
      "Epoch  20\n",
      "Epoch  21\n",
      "Epoch  22\n",
      "Epoch  23\n",
      "Epoch  24\n",
      "Epoch  25\n",
      "Epoch  26\n",
      "Epoch  27\n",
      "Epoch  28\n",
      "Epoch  29\n",
      "Epoch  30\n",
      "Epoch  31\n",
      "Epoch  32\n",
      "Epoch  33\n",
      "Epoch  34\n",
      "Epoch  35\n",
      "Epoch  36\n",
      "Epoch  37\n",
      "Epoch  38\n",
      "Epoch  39\n",
      "Epoch  40\n",
      "Epoch  41\n",
      "Epoch  42\n",
      "Epoch  43\n",
      "Epoch  44\n",
      "Epoch  45\n",
      "Epoch  46\n",
      "Epoch  47\n",
      "Epoch  48\n",
      "Epoch  49\n",
      "Epoch  50\n",
      "Epoch  51\n",
      "Epoch  52\n",
      "Epoch  53\n",
      "Epoch  54\n",
      "Epoch  55\n",
      "Epoch  56\n",
      "Epoch  57\n",
      "Epoch  58\n",
      "Epoch  59\n",
      "Epoch  60\n",
      "Epoch  61\n",
      "Epoch  62\n",
      "Epoch  63\n",
      "Epoch  64\n",
      "Epoch  65\n",
      "Epoch  66\n",
      "Epoch  67\n",
      "Epoch  68\n",
      "Epoch  69\n",
      "Epoch  70\n",
      "Epoch  71\n",
      "Epoch  72\n",
      "Epoch  73\n",
      "Epoch  74\n",
      "Epoch  75\n",
      "Epoch  76\n",
      "Epoch  77\n",
      "Epoch  78\n",
      "Epoch  79\n",
      "Epoch  80\n",
      "Epoch  81\n",
      "Epoch  82\n",
      "Epoch  83\n",
      "Epoch  84\n",
      "Epoch  85\n",
      "Epoch  86\n",
      "Epoch  87\n",
      "Epoch  88\n",
      "Epoch  89\n",
      "Epoch  90\n",
      "Epoch  91\n",
      "Epoch  92\n",
      "Epoch  93\n",
      "Epoch  94\n",
      "Epoch  95\n",
      "Epoch  96\n",
      "Epoch  97\n",
      "Epoch  98\n",
      "Epoch  99\n",
      "Epoch  100\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "xhat_miwae = np.copy(xhat_0)\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    for xhat_0_batch, mask_batch in train_dataset:\n",
    "        gradient_step_miwae(xhat_0_batch, mask_batch,K = 20) # Adam iteration\n",
    "  \n",
    "    print('Epoch  %g' %epoch)\n",
    "    \n",
    "    if epoch == 100:\n",
    "        for i in range(n):\n",
    "            xhat_miwae[i,:]  = miwae_impute(xhat_0[i,:].reshape([1,p]), mask[i,:].reshape([1,p]), kind = \"single\",L = 10000).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96abbd17-b225-406b-96f0-651a363a2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(xhat_miwae, columns = xmiss.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3455b67a-b04d-4f20-8bdf-99b1539aea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('MIWAE_50.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b011b-0dea-4b79-824c-91a2a80b4ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
